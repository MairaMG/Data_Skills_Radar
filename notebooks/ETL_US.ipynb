{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00993d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1709eefb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/gsearch_jobs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e57d96b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36470, 27)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c0eb5e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>via</th>\n",
       "      <th>description</th>\n",
       "      <th>extensions</th>\n",
       "      <th>job_id</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>...</th>\n",
       "      <th>commute_time</th>\n",
       "      <th>salary_pay</th>\n",
       "      <th>salary_rate</th>\n",
       "      <th>salary_avg</th>\n",
       "      <th>salary_min</th>\n",
       "      <th>salary_max</th>\n",
       "      <th>salary_hourly</th>\n",
       "      <th>salary_yearly</th>\n",
       "      <th>salary_standardized</th>\n",
       "      <th>description_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28996</th>\n",
       "      <td>28996</td>\n",
       "      <td>1828</td>\n",
       "      <td>Business Intelligence Analyst</td>\n",
       "      <td>Allied OneSource</td>\n",
       "      <td>Olathe, KS</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Do you have a curious mind where you are able ...</td>\n",
       "      <td>['11 hours ago', 'Full-time']</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJCdXNpbmVzcyBJbnRlbGxpZ2VuY2...</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['sql']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4480</th>\n",
       "      <td>4480</td>\n",
       "      <td>282</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>SP Software Solutions</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Position: Data Scientist\\n\\nLocation: Santa Cl...</td>\n",
       "      <td>['12 hours ago', 'Work from home', 'Contractor']</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEYXRhIFNjaWVudGlzdCIsImh0aW...</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['pytorch', 'tensorflow', 'keras', 'python']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26999</th>\n",
       "      <td>26999</td>\n",
       "      <td>3063</td>\n",
       "      <td>Data Entry Clerk II</td>\n",
       "      <td>LeadStack Inc.</td>\n",
       "      <td>United States</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>**Please note that *** requires a *** per hour...</td>\n",
       "      <td>['5 hours ago', 'Full-time', 'No degree mentio...</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEYXRhIEVudHJ5IENsZXJrIElJIi...</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  index                          title  \\\n",
       "28996       28996   1828  Business Intelligence Analyst   \n",
       "4480         4480    282                 Data Scientist   \n",
       "26999       26999   3063            Data Entry Clerk II   \n",
       "\n",
       "                company_name       location           via  \\\n",
       "28996       Allied OneSource     Olathe, KS  via LinkedIn   \n",
       "4480   SP Software Solutions      Anywhere   via LinkedIn   \n",
       "26999         LeadStack Inc.  United States  via LinkedIn   \n",
       "\n",
       "                                             description  \\\n",
       "28996  Do you have a curious mind where you are able ...   \n",
       "4480   Position: Data Scientist\\n\\nLocation: Santa Cl...   \n",
       "26999  **Please note that *** requires a *** per hour...   \n",
       "\n",
       "                                              extensions  \\\n",
       "28996                      ['11 hours ago', 'Full-time']   \n",
       "4480    ['12 hours ago', 'Work from home', 'Contractor']   \n",
       "26999  ['5 hours ago', 'Full-time', 'No degree mentio...   \n",
       "\n",
       "                                                  job_id  \\\n",
       "28996  eyJqb2JfdGl0bGUiOiJCdXNpbmVzcyBJbnRlbGxpZ2VuY2...   \n",
       "4480   eyJqb2JfdGl0bGUiOiJEYXRhIFNjaWVudGlzdCIsImh0aW...   \n",
       "26999  eyJqb2JfdGl0bGUiOiJEYXRhIEVudHJ5IENsZXJrIElJIi...   \n",
       "\n",
       "                                               thumbnail  ... commute_time  \\\n",
       "28996  https://encrypted-tbn0.gstatic.com/images?q=tb...  ...          NaN   \n",
       "4480   https://encrypted-tbn0.gstatic.com/images?q=tb...  ...          NaN   \n",
       "26999  https://encrypted-tbn0.gstatic.com/images?q=tb...  ...          NaN   \n",
       "\n",
       "      salary_pay salary_rate salary_avg salary_min salary_max salary_hourly  \\\n",
       "28996        NaN         NaN        NaN        NaN        NaN           NaN   \n",
       "4480         NaN         NaN        NaN        NaN        NaN           NaN   \n",
       "26999        NaN         NaN        NaN        NaN        NaN           NaN   \n",
       "\n",
       "       salary_yearly salary_standardized  \\\n",
       "28996            NaN                 NaN   \n",
       "4480             NaN                 NaN   \n",
       "26999            NaN                 NaN   \n",
       "\n",
       "                                 description_tokens  \n",
       "28996                                       ['sql']  \n",
       "4480   ['pytorch', 'tensorflow', 'keras', 'python']  \n",
       "26999                                            []  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853deebf",
   "metadata": {},
   "source": [
    "## Drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d2dc4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['Unnamed: 0','index','thumbnail','posted_at','commute_time','search_term','salary','salary_pay','salary_rate','salary_min','salary_max','salary_avg','salary_hourly','salary_yearly','extensions']\n",
    "df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ed9042",
   "metadata": {},
   "source": [
    "## Drop duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "791d2139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>via</th>\n",
       "      <th>description</th>\n",
       "      <th>job_id</th>\n",
       "      <th>schedule_type</th>\n",
       "      <th>work_from_home</th>\n",
       "      <th>date_time</th>\n",
       "      <th>search_location</th>\n",
       "      <th>salary_standardized</th>\n",
       "      <th>description_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11973</th>\n",
       "      <td>Business Systems Data Analyst</td>\n",
       "      <td>MTC Holding Corporation</td>\n",
       "      <td>Shawnee, KS</td>\n",
       "      <td>via Vacancies For Col U Fans</td>\n",
       "      <td>Description:\\n\\nPurpose...\\n\\nThe Business Sys...</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJCdXNpbmVzcyBTeXN0ZW1zIERhdG...</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-22 03:00:25.924344</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31389</th>\n",
       "      <td>Data Conversion Analyst</td>\n",
       "      <td>ABC Fitness Solutions</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Company : ABC Fitness Solutions\\n\\nIt's fun to...</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEYXRhIENvbnZlcnNpb24gQW5hbH...</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>True</td>\n",
       "      <td>2022-12-15 04:00:39.906292</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['excel', 'sql']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21384</th>\n",
       "      <td>Healthcare Data Analyst</td>\n",
       "      <td>Gainwell Technologies LLC</td>\n",
       "      <td>United States</td>\n",
       "      <td>via BeBee</td>\n",
       "      <td>Be part of a team that unleashes the power of ...</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJIZWFsdGhjYXJlIERhdGEgQW5hbH...</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-02-11 04:00:36.927315</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['sql']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               title               company_name  \\\n",
       "11973  Business Systems Data Analyst    MTC Holding Corporation   \n",
       "31389        Data Conversion Analyst      ABC Fitness Solutions   \n",
       "21384        Healthcare Data Analyst  Gainwell Technologies LLC   \n",
       "\n",
       "               location                           via  \\\n",
       "11973    Shawnee, KS     via Vacancies For Col U Fans   \n",
       "31389          Anywhere                  via LinkedIn   \n",
       "21384     United States                     via BeBee   \n",
       "\n",
       "                                             description  \\\n",
       "11973  Description:\\n\\nPurpose...\\n\\nThe Business Sys...   \n",
       "31389  Company : ABC Fitness Solutions\\n\\nIt's fun to...   \n",
       "21384  Be part of a team that unleashes the power of ...   \n",
       "\n",
       "                                                  job_id schedule_type  \\\n",
       "11973  eyJqb2JfdGl0bGUiOiJCdXNpbmVzcyBTeXN0ZW1zIERhdG...     Full-time   \n",
       "31389  eyJqb2JfdGl0bGUiOiJEYXRhIENvbnZlcnNpb24gQW5hbH...     Full-time   \n",
       "21384  eyJqb2JfdGl0bGUiOiJIZWFsdGhjYXJlIERhdGEgQW5hbH...     Full-time   \n",
       "\n",
       "      work_from_home                   date_time search_location  \\\n",
       "11973            NaN  2023-06-22 03:00:25.924344   United States   \n",
       "31389           True  2022-12-15 04:00:39.906292   United States   \n",
       "21384            NaN  2023-02-11 04:00:36.927315   United States   \n",
       "\n",
       "       salary_standardized description_tokens  \n",
       "11973                  NaN                 []  \n",
       "31389                  NaN   ['excel', 'sql']  \n",
       "21384                  NaN            ['sql']  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find duplicates based on 'title' and 'company' columns (in this case cannot use job_id as in some cases any minimal difference in time of publication gives a new job_id)\n",
    "duplicate_mask = df.duplicated(subset=['title', 'company_name'], keep=False)\n",
    "\n",
    "# Get both original and duplicate rows for double-check\n",
    "original_and_duplicates = df[duplicate_mask].sort_values(by=['title', 'company_name'])\n",
    "original_and_duplicates.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f4fdfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the duplicate rows\n",
    "df.drop_duplicates(subset=['title', 'company_name'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c92f74",
   "metadata": {},
   "source": [
    "## Creating a New Column: \"experience_level\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3bc1dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_experience(title):\n",
    "    title_lower = title.lower()\n",
    "    if any(word in title_lower for word in [ 'intern','internship']):\n",
    "        return 'Internship'\n",
    "    elif any(word in title_lower for word in ['manager', 'executive', 'principal', 'staff']):\n",
    "        return 'Manager'\n",
    "    elif any(word in title_lower for word in ['director']):\n",
    "        return 'Director'\n",
    "    elif any(word in title_lower for word in ['mid-senior','mid level','mid-level','ii','specialist']):\n",
    "        return 'Mid-Senior'\n",
    "    elif any(word in title_lower for word in ['jr', 'jr.','junior','entry', 'associate','1']):\n",
    "        return 'Junior'\n",
    "    elif any(word in title_lower for word in ['sr.', 'sr', 'senior','exper','3','4','lead','steward']):\n",
    "        return 'Senior'\n",
    "    elif any(word in title for word in ['III','IV']):\n",
    "        return 'Senior'\n",
    "    elif 'II' in title:\n",
    "        return 'Mid-Senior'\n",
    "    elif re.search(r'\\bI\\b', title):\n",
    "        return 'Junior'\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e188915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to create the 'experience_level' column\n",
    "df['experience_level'] = df['title'].apply(categorize_experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5548b307",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "experience_level\n",
       "Senior        4796\n",
       "Junior        1250\n",
       "Mid-Senior    1221\n",
       "Manager        778\n",
       "Internship     286\n",
       "Director        86\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['experience_level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92e363cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['experience_level'].fillna('Not-Specified', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07844a0b",
   "metadata": {},
   "source": [
    "## Cleaning column: \"title\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c12302e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_title(title):\n",
    "    title_lower = title.lower()\n",
    "    if 'machine' in title_lower:\n",
    "        return 'Machine Learning Engineer'\n",
    "    elif 'artificial' in title_lower or 'AI' in title or 'ML' in title:\n",
    "        return 'Machine Learning Engineer'\n",
    "    elif 'cloud' in title_lower:\n",
    "        return 'Cloud Engineer'\n",
    "    elif 'software' in title_lower:\n",
    "        return 'Software Engineer'\n",
    "    elif 'dev' in title_lower:\n",
    "        return 'Software Engineer'\n",
    "    elif re.search(r'\\bBI\\b', title) or re.search(r'\\bbusiness\\s*(?!data\\s*)\\w*\\s*analyst\\b|\\bbusiness\\s*(?!data\\s*)\\w*\\s*intelligence\\b|\\bfinancial\\s*analyst\\b', title_lower):\n",
    "        return 'Business Analyst'\n",
    "    elif 'engineer' in title_lower and 'data' in title_lower:\n",
    "        return 'Data Engineer'\n",
    "    elif 'software' in title_lower:\n",
    "        return 'Software Engineer'\n",
    "    elif 'scien' in title_lower:\n",
    "        return 'Data Scientist'\n",
    "    elif re.search(r'\\bdata\\b|\\banalytics?\\b', title_lower):\n",
    "        return 'Data Analyst'\n",
    "    elif re.search(r'\\bdata\\b.*\\b(analyst|analytics|analysis)\\b|\\banalytics?\\b', title_lower):\n",
    "        return 'Data Analyst'\n",
    "    elif 'tableau' in title_lower or 'R' in title or 'forecast' in title_lower or 'excel' in title_lower or 'trends' in title_lower or 'regression' in title_lower or 'intelligence' in title_lower or 'digital' in title_lower or 'spss' in title_lower or 'numpy' in title_lower or 'data' in title_lower :\n",
    "        return 'Data Analyst'\n",
    "    elif 'system' in title_lower:\n",
    "        return 'Software Engineer'\n",
    "    elif 'program' in title_lower:\n",
    "        return 'Software Engineer'\n",
    "    elif 'backend' in title_lower:\n",
    "        return 'Software Engineer'\n",
    "    elif 'frontend' in title_lower:\n",
    "        return 'Software Engineer'\n",
    "    elif 'full' in title_lower:\n",
    "        return 'Software Engineer'\n",
    "    \n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa99ed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function and create the 'title_cleaned' column in clear data role categories \n",
    "df.loc[:, 'title_cleaned'] = df['title'].apply(clean_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe1ec75a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title_cleaned\n",
       "Data Analyst                 16075\n",
       "Business Analyst              1376\n",
       "Data Scientist                1138\n",
       "Data Engineer                  599\n",
       "Software Engineer              520\n",
       "Machine Learning Engineer      136\n",
       "Cloud Engineer                  71\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title_cleaned'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bcdae6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1491"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title_cleaned'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51242910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19915, 14)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(subset=['title_cleaned'], inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb8acf1",
   "metadata": {},
   "source": [
    "## Creating a New Column: \"Role\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2582b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_role_name(row):\n",
    "    title_cleaned = row['title_cleaned']\n",
    "    experience_level = row['experience_level']\n",
    "    \n",
    "    if experience_level == \"Not-Specified\":\n",
    "        return title_cleaned\n",
    "    elif title_cleaned is None:\n",
    "        return None\n",
    "    else:\n",
    "        return f\"{title_cleaned} {experience_level}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4cf3fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['role'] = df.apply(get_role_name, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afe955e",
   "metadata": {},
   "source": [
    "## Cleaning column: \"description_tokens\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35b00ac9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Renaming the column\n",
    "df.rename(columns={'description_tokens': 'extracted_skills'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febbc1ce",
   "metadata": {},
   "source": [
    "## Cleaning column: \"location\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7075a8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'location': 'original_location'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd48cca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of state names and abbreviations\n",
    "state_name_to_abbreviation = {\n",
    "    'Alabama': 'AL', 'Alaska': 'AK', 'Arizona': 'AZ', 'Arkansas': 'AR', 'California': 'CA', 'Colorado': 'CO',\n",
    "    'Connecticut': 'CT', 'Delaware': 'DE', 'Florida': 'FL', 'Georgia': 'GA', 'Hawaii': 'HI', 'Idaho': 'ID',\n",
    "    'Illinois': 'IL', 'Indiana': 'IN', 'Iowa': 'IA', 'Kansas': 'KS', 'Kentucky': 'KY', 'Louisiana': 'LA',\n",
    "    'Maine': 'ME', 'Maryland': 'MD', 'Massachusetts': 'MA', 'Michigan': 'MI', 'Minnesota': 'MN',\n",
    "    'Mississippi': 'MS', 'Missouri': 'MO', 'Montana': 'MT', 'Nebraska': 'NE', 'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH', 'New Jersey': 'NJ', 'New Mexico': 'NM', 'New York': 'NY', 'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND', 'Ohio': 'OH', 'Oklahoma': 'OK', 'Oregon': 'OR', 'Pennsylvania': 'PA',\n",
    "    'Rhode Island': 'RI', 'South Carolina': 'SC', 'South Dakota': 'SD', 'Tennessee': 'TN', 'Texas': 'TX',\n",
    "    'Utah': 'UT', 'Vermont': 'VT', 'Virginia': 'VA', 'Washington': 'WA', 'West Virginia': 'WV', 'Wisconsin': 'WI',\n",
    "    'Wyoming': 'WY'\n",
    "}\n",
    "\n",
    "# Function to replace state names with abbreviations\n",
    "def replace_state_with_abbreviation(text):\n",
    "    if pd.isna(text):\n",
    "        return text  \n",
    "    # Removing additional text after the state abbreviation in ()\n",
    "    text = re.sub(r'\\s*\\(\\+\\d+\\s*other[s]?\\)', '', str(text))\n",
    "    for state_name, state_abbr in state_name_to_abbreviation.items():\n",
    "        if state_name.lower() in text.lower():\n",
    "            return state_abbr\n",
    "    # Return non-state values as is\n",
    "    return text  \n",
    "\n",
    "# Extract information after comma and removing leading andtrailing spaces\n",
    "df['original_location'] = df['original_location'].fillna(np.nan)  # Fill NaN values explicitly\n",
    "df['original_location'] = df['original_location'].str.split(',').str[-1].str.strip()\n",
    "\n",
    "# Update the entire column to 'Not Specified' if it contains the phrase 'United States'\n",
    "df.loc[df['original_location'].str.contains('United States', case=False, na=False), 'original_location'] = 'Not-Specified'\n",
    "\n",
    "# Replace state names with abbreviations\n",
    "df['original_location'] = df['original_location'].apply(replace_state_with_abbreviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ab9a38c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['original_location'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae59655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluated case by case because they were just 14\n",
    "df['original_location'].fillna('KS', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5cf5b371",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mairagutierrez/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mairagutierrez/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Ensure NLTK resources are downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Set of English stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b74a0f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to tokenize descriptions and remove stopwords\n",
    "def tokenize_and_remove_stopwords(description):\n",
    "    tokens = word_tokenize(description.lower())\n",
    "    return [token for token in tokens if token.isalpha() and token not in stop_words]\n",
    "\n",
    "# Function to find the first state in a text\n",
    "def find_first_state(text):\n",
    "    for state in state_name_to_abbreviation.keys():\n",
    "        if re.search(r'\\b' + state + r'\\b', text):\n",
    "            return state_name_to_abbreviation[state]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02260cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize descriptions and remove stopwords\n",
    "df['description_tokens'] = df['description'].apply(tokenize_and_remove_stopwords)\n",
    "\n",
    "# Find the first state in the tokenized descriptions and store it in a new column\n",
    "df['location'] = df['description'].apply(find_first_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c13da167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace null values in 'location' with values from 'original_location'\n",
    "df['location'].fillna(df['original_location'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36a47d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_abbreviation_to_name = {\n",
    "    'AL': 'Alabama', 'AK': 'Alaska', 'AZ': 'Arizona', 'AR': 'Arkansas', 'CA': 'California', 'CO': 'Colorado',\n",
    "    'CT': 'Connecticut','DC':'Washington DC', 'DE': 'Delaware', 'FL': 'Florida', 'GA': 'Georgia', 'HI': 'Hawaii', 'ID': 'Idaho',\n",
    "    'IL': 'Illinois', 'IN': 'Indiana', 'IA': 'Iowa', 'KS': 'Kansas', 'KY': 'Kentucky', 'LA': 'Louisiana',\n",
    "    'ME': 'Maine', 'MD': 'Maryland', 'MA': 'Massachusetts', 'MI': 'Michigan', 'MN': 'Minnesota',\n",
    "    'MS': 'Mississippi', 'MO': 'Missouri', 'MT': 'Montana', 'NE': 'Nebraska', 'NV': 'Nevada',\n",
    "    'NH': 'New Hampshire', 'NJ': 'New Jersey', 'NM': 'New Mexico', 'NY': 'New York', 'NC': 'North Carolina',\n",
    "    'ND': 'North Dakota', 'OH': 'Ohio', 'OK': 'Oklahoma', 'OR': 'Oregon', 'PA': 'Pennsylvania',\n",
    "    'RI': 'Rhode Island', 'SC': 'South Carolina', 'SD': 'South Dakota', 'TN': 'Tennessee', 'TX': 'Texas',\n",
    "    'UT': 'Utah', 'VT': 'Vermont', 'VA': 'Virginia', 'WA': 'Washington', 'WV': 'West Virginia',\n",
    "    'WI': 'Wisconsin', 'WY': 'Wyoming'\n",
    "}\n",
    "\n",
    "def replace_state_abbreviations(location):\n",
    "    if location.upper() in state_abbreviation_to_name:\n",
    "        return state_abbreviation_to_name[location.upper()]\n",
    "    else:\n",
    "        return location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e70e193a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location'] = df['location'].apply(replace_state_abbreviations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27f8953b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>original_location</th>\n",
       "      <th>via</th>\n",
       "      <th>description</th>\n",
       "      <th>job_id</th>\n",
       "      <th>schedule_type</th>\n",
       "      <th>work_from_home</th>\n",
       "      <th>date_time</th>\n",
       "      <th>search_location</th>\n",
       "      <th>salary_standardized</th>\n",
       "      <th>extracted_skills</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>title_cleaned</th>\n",
       "      <th>role</th>\n",
       "      <th>description_tokens</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Meta</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>In the intersection of compliance and analytic...</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QiLCJodGlkb2...</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-08-04 03:00:13.797776</td>\n",
       "      <td>United States</td>\n",
       "      <td>122000.0</td>\n",
       "      <td>['r', 'tableau', 'sql', 'python']</td>\n",
       "      <td>Not-Specified</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>[intersection, compliance, analytics, seeking,...</td>\n",
       "      <td>Anywhere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>ATC</td>\n",
       "      <td>Not-Specified</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Job Title: Entry Level Business Analyst / Prod...</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QiLCJodGlkb2...</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-04 03:00:13.797776</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Not-Specified</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>[job, title, entry, level, business, analyst, ...</td>\n",
       "      <td>Not-Specified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          title company_name original_location           via  \\\n",
       "0  Data Analyst         Meta          Anywhere  via LinkedIn   \n",
       "1  Data Analyst          ATC     Not-Specified  via LinkedIn   \n",
       "\n",
       "                                         description  \\\n",
       "0  In the intersection of compliance and analytic...   \n",
       "1  Job Title: Entry Level Business Analyst / Prod...   \n",
       "\n",
       "                                              job_id schedule_type  \\\n",
       "0  eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QiLCJodGlkb2...     Full-time   \n",
       "1  eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QiLCJodGlkb2...     Full-time   \n",
       "\n",
       "  work_from_home                   date_time search_location  \\\n",
       "0           True  2023-08-04 03:00:13.797776   United States   \n",
       "1            NaN  2023-08-04 03:00:13.797776   United States   \n",
       "\n",
       "   salary_standardized                   extracted_skills experience_level  \\\n",
       "0             122000.0  ['r', 'tableau', 'sql', 'python']    Not-Specified   \n",
       "1                  NaN                                 []    Not-Specified   \n",
       "\n",
       "  title_cleaned          role  \\\n",
       "0  Data Analyst  Data Analyst   \n",
       "1  Data Analyst  Data Analyst   \n",
       "\n",
       "                                  description_tokens       location  \n",
       "0  [intersection, compliance, analytics, seeking,...       Anywhere  \n",
       "1  [job, title, entry, level, business, analyst, ...  Not-Specified  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2bb9458d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Anywhere', 'Not-Specified', 'Kansas', 'Oklahoma', 'Arkansas',\n",
       "       'Missouri', 'Illinois', 'Florida', 'Hawaii', 'New York', 'Alaska',\n",
       "       'Ohio', 'California', 'Indiana', 'Pennsylvania', 'New Jersey',\n",
       "       'Arizona', 'New Mexico', 'Massachusetts', 'Idaho', 'Washington',\n",
       "       'Texas', 'Maryland', 'Alabama', 'Georgia', 'Connecticut', 'Maine',\n",
       "       'North Carolina', 'Rhode Island', 'Minnesota', 'North Dakota',\n",
       "       'Oregon', 'Virginia', 'Colorado', 'Michigan', 'Nevada', 'Nebraska',\n",
       "       'Utah', 'South Carolina', 'Louisiana', 'Delaware', 'Wisconsin',\n",
       "       'South Dakota', 'Mississippi', 'Iowa', 'Kentucky', 'Vermont',\n",
       "       'Tennessee', 'Wyoming', 'Montana', 'New Hampshire',\n",
       "       'Washington DC'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['location'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f013a0",
   "metadata": {},
   "source": [
    "## Cleaning column: \"via\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e3fd7f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['via'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d459e64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>original_location</th>\n",
       "      <th>via</th>\n",
       "      <th>description</th>\n",
       "      <th>job_id</th>\n",
       "      <th>schedule_type</th>\n",
       "      <th>work_from_home</th>\n",
       "      <th>date_time</th>\n",
       "      <th>search_location</th>\n",
       "      <th>salary_standardized</th>\n",
       "      <th>extracted_skills</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>title_cleaned</th>\n",
       "      <th>role</th>\n",
       "      <th>description_tokens</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Jobs Near Me</td>\n",
       "      <td>MO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Analyst Jobs Near Me in Joplin, Missouri\\...</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QiLCJodGlkb2...</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-17 03:00:27.163001</td>\n",
       "      <td>United States</td>\n",
       "      <td>31200.0</td>\n",
       "      <td>['javascript', 'sql', 'sas', 'excel', 'spss']</td>\n",
       "      <td>Not-Specified</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>[data, analyst, jobs, near, joplin, missouri, ...</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            title  company_name original_location  via  \\\n",
       "155  Data Analyst  Jobs Near Me                MO  NaN   \n",
       "\n",
       "                                           description  \\\n",
       "155  Data Analyst Jobs Near Me in Joplin, Missouri\\...   \n",
       "\n",
       "                                                job_id schedule_type  \\\n",
       "155  eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QiLCJodGlkb2...     Full-time   \n",
       "\n",
       "    work_from_home                   date_time search_location  \\\n",
       "155            NaN  2023-08-17 03:00:27.163001   United States   \n",
       "\n",
       "     salary_standardized                               extracted_skills  \\\n",
       "155              31200.0  ['javascript', 'sql', 'sas', 'excel', 'spss']   \n",
       "\n",
       "    experience_level title_cleaned          role  \\\n",
       "155    Not-Specified  Data Analyst  Data Analyst   \n",
       "\n",
       "                                    description_tokens  location  \n",
       "155  [data, analyst, jobs, near, joplin, missouri, ...  Missouri  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_locations = df[df['via'].isnull()]\n",
    "null_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd652bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['via'].fillna('Linkedin', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "73fb2a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting rid of 'via' at the beginning of the strings\n",
    "df['via'] = df['via'].str.replace(r'^via', '', regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "539742f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "via\n",
       "LinkedIn       7326\n",
       "Upwork         3505\n",
       "BeBee          2281\n",
       "Trabajo.org    1466\n",
       "Indeed         1169\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 5 job search websites\n",
    "df['via'].value_counts().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b732d6c",
   "metadata": {},
   "source": [
    "## Cleaning column: \"schedule_type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be46f8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['schedule_type'].str.contains('internship', case=False, na=False), 'schedule_type'] = 'Internship'\n",
    "df.loc[df['schedule_type'].str.contains('contractor|tempwork|temp work', case=False, na=False), 'schedule_type'] = 'Contractor'\n",
    "df.loc[df['schedule_type'].str.contains('full-time', case=False, na=False), 'schedule_type'] = 'Full-time'\n",
    "df.loc[df['schedule_type'].str.contains('part-time|volunteer', case=False, na=False), 'schedule_type'] = 'Part-time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c44bcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['schedule_type'].fillna('Full-time', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4cd85c",
   "metadata": {},
   "source": [
    "## Cleaning column:  \"work_from_home\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a9937b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'Work-Modality' based on modifications in 'work_from_home'\n",
    "df['work_modality'] = df['work_from_home'].fillna('On-Site')\n",
    "df['work_modality'].replace(True, 'Remote', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8e07f97f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "work_modality\n",
       "Remote     10310\n",
       "On-Site     9605\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['work_modality'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977853b3",
   "metadata": {},
   "source": [
    "## Cleaning column:  \"date_time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c74cba54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming 'date_time' column to date format without hours\n",
    "df['date_time'] = pd.to_datetime(df['date_time']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eefda74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'date_time': 'posted_date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a8630b",
   "metadata": {},
   "source": [
    "## Cleaning column:  \"salary_standardized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca8ae978",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      3562.000000\n",
       "mean      94203.002925\n",
       "std       45405.587652\n",
       "min       15080.000000\n",
       "25%       62400.000000\n",
       "50%       88400.000000\n",
       "75%      119600.000000\n",
       "max      624000.000000\n",
       "Name: salary_standardized, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['salary_standardized'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282321eb",
   "metadata": {},
   "source": [
    "## Make uniform my datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c6cff7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['work_from_home','description','original_location','description_tokens']\n",
    "df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b19f0ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrenged columns\n",
    "new_order = ['job_id','title','experience_level','title_cleaned','role','work_modality','company_name','location','via','schedule_type','salary_standardized','posted_date','extracted_skills','search_location']\n",
    "df = df[new_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "292c36b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['job_id', 'title', 'experience_level', 'title_cleaned', 'role',\n",
       "       'work_modality', 'company_name', 'location', 'via', 'schedule_type',\n",
       "       'salary_standardized', 'posted_date', 'extracted_skills',\n",
       "       'search_location'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d641129",
   "metadata": {},
   "source": [
    "## Save Dataframe: Job Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3b4c34e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/us_jobposts.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "284886dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19915, 14)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072dd993",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironhack",
   "language": "python",
   "name": "ironhack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
