{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1aaec304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pymysql\n",
    "import sqlalchemy as alch\n",
    "from dotenv import load_dotenv\n",
    "from getpass import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "355232c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ba689e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_password = os.getenv(\"Password\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c543e766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "df = pd.read_csv('../data/us_jobposts.csv',encoding='utf-8')\n",
    "\n",
    "# Make the array column an actual array\n",
    "df['extracted_skills'] = df['extracted_skills'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "75d1b560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_engine():\n",
    "    \n",
    "    sql_password = os.getenv(\"Password\")  \n",
    "    dbName = \"us_jobposts\"\n",
    "    connectionData = f\"mysql+pymysql://root:{sql_password}@localhost:3306/{dbName}?charset=utf8mb4&use_unicode=1\"\n",
    "    engine = alch.create_engine(connectionData)\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "70299df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inserting skills\n",
    "\n",
    "def get_skills_with_ids():\n",
    "    unique_skills = set()\n",
    "    for index, row in df.iterrows():\n",
    "        skills_lst = row['extracted_skills']\n",
    "        for skill in skills_lst:\n",
    "            if skill:\n",
    "                unique_skills.add(skill)\n",
    "    \n",
    "    unique_skills_lst = list(unique_skills)\n",
    "    skills_with_ids = [(index+1, skill) for index, skill in enumerate(unique_skills_lst)]\n",
    "    return skills_with_ids\n",
    "\n",
    "\n",
    "skills_with_ids = get_skills_with_ids()\n",
    "\n",
    "# Create dataframe to make it easier to insert\n",
    "df_skills_with_ids = pd.DataFrame(skills_with_ids, columns=['id', 'skill'])\n",
    "\n",
    "# Load skills into its own table\n",
    "df_skills_with_ids.to_sql(\"skills\", if_exists=\"append\", con=engine, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8057193f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19915"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inserting jobs\n",
    "df.drop('extracted_skills', axis=1)\n",
    "df_for_insert = df.copy()\n",
    "del df_for_insert['extracted_skills']\n",
    "df_for_insert.to_sql(\"jobs\", if_exists=\"append\", con=engine, index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5d50939d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62391"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert jobs x skills\n",
    "\n",
    "skills_map = {item[1]:item[0] for item in skills_with_ids}\n",
    "\n",
    "job_id_to_skills_lst = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    job_id = row['job_id']\n",
    "    skills = row['extracted_skills']\n",
    "    for skill in skills:\n",
    "        skill_id = skills_map[skill]\n",
    "        if not skill_id:\n",
    "            print(skill)\n",
    "            break\n",
    "        job_id_to_skills_lst.append((job_id, skill_id))\n",
    "\n",
    "df_job_id_to_skills = pd.DataFrame(job_id_to_skills_lst, columns=['job_id', 'skill_id'])\n",
    "df_job_id_to_skills.to_sql(\"jobs_x_skills\", if_exists=\"append\", con=engine, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6311540c",
   "metadata": {},
   "source": [
    "## Other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4545dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Count the most in-demand skills\n",
    "skills_demand = skills_df['extracted_skills'].explode().value_counts()\n",
    "skills_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c160fe0a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 3. Frequency of skill sets for Junior level\n",
    "ba_junior_skills = skills_df[skills_df['role'] == 'Business Analyst Junior']['extracted_skills'].explode().value_counts()\n",
    "ba_junior_skills.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44313330",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_junior_skills = skills_df[skills_df['role'] == 'Business Analyst Junior']['extracted_skills'].explode().value_counts()\n",
    "ba_junior_skills.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d446bda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_senior_skills = skills_df[skills_df['experience_level'] == 'Mid-Senior']['extracted_skills'].explode().value_counts()\n",
    "mid_senior_skills.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4f96a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "senior_skills = skills_df[skills_df['experience_level'] == 'Senior']['extracted_skills'].explode().value_counts()\n",
    "senior_skills.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42f5f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0f68a5d",
   "metadata": {},
   "source": [
    "## Change DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5e2056",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/spain_jobposts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c754c7",
   "metadata": {},
   "source": [
    "#### Keyword Clustering and Skill Grouping:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc22664a",
   "metadata": {},
   "source": [
    "Create clusters or categories of skills that often appear together in job postings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce331dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To perform keyword clustering and skill grouping, we can use a clustering algorithm like K-means on the skills data.\n",
    "# We'll first load the dataset, process the 'extracted_skills' column, and then apply K-means clustering.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from ast import literal_eval\n",
    "\n",
    "# Process the 'extracted_skills' column\n",
    "# Convert the string representation of lists into actual lists\n",
    "df['extracted_skills'] = df['extracted_skills'].apply(literal_eval)\n",
    "\n",
    "# Join the lists of skills into a single string per row\n",
    "df['skills_str'] = df['extracted_skills'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Apply TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(df['skills_str'])\n",
    "\n",
    "# Apply K-means clustering\n",
    "num_clusters = 5  # Adjust the number of clusters as needed\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Assign the cluster labels to the DataFrame\n",
    "df['cluster'] = kmeans.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210f2f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088b89dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# Apply PCA to reduce dimensions to 2D for visualization\n",
    "pca = PCA(n_components=2)\n",
    "reduced_X = pca.fit_transform(X.toarray())\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(reduced_X[:, 0], reduced_X[:, 1], c=df['cluster'], cmap='viridis', marker='o')\n",
    "plt.title('Skill Clusters')\n",
    "plt.xlabel('PCA Feature 1')\n",
    "plt.ylabel('PCA Feature 2')\n",
    "plt.colorbar(label='Cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df499813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Geographical distribution of job postings\n",
    "location_distribution = df['location'].value_counts()\n",
    "location_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f70a978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Ranking companies by number of job postings\n",
    "company_ranking = df['company_name'].value_counts()\n",
    "company_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4596ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Average number of skills required per company\n",
    "df['num_skills'] = df['extracted_skills'].apply(lambda x: len(x))\n",
    "avg_skills_company = df.groupby('company_name')['num_skills'].mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dd124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Distribution of job roles\n",
    "role_distribution = df['role'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ec5a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Experience levels required for each role\n",
    "experience_role = df.groupby('role')['experience_level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96c3729",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironhack",
   "language": "python",
   "name": "ironhack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
